{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0c179a",
   "metadata": {},
   "source": [
    "# Data synthesis pipeline\n",
    "Following the steps in this Notebook will allow you to synthesize data as .csv input.<br>\n",
    "All names under chapter <b>2. Variables</b> should be checked and changed if necessary.<br>\n",
    "Processing and synthesizing the data may take a while depending on the chosen dataset.<br>\n",
    "Results are stored in the \\Results folder of this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec34c39",
   "metadata": {},
   "source": [
    "## 1. Environment\n",
    "Install required python package via pip (shapely, geopandas). Warnings may be ignored. If you encounter errors, try installing the packages via Anconda Prompt (from the Start menu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2a8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install synthgauge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98ec64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install geopandas --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d8672",
   "metadata": {},
   "source": [
    "### 1.1 Restart Kernel or comment out .plot_functions\n",
    "To continue with the next section, restart the kernel or comment out the line: \"from Pipeline.plotting.plot_functions import map_plotter, gemeente_lader, distribution_comparison\" (note that you won't be able to execute chapter 5.4). To restart the kernel, go to \"Kernel\" in the toolbar and select \"Restart\". After restart you can execute the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced314c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:44:20.736025Z",
     "start_time": "2023-01-30T10:43:55.192897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all the required modules. Do not change these settings.\n",
    "import os\n",
    "import subprocess\n",
    "import Pipeline.final_score\n",
    "\n",
    "from Pipeline.full_data_process import full_data_process\n",
    "from Pipeline.df_compare import *\n",
    "from Pipeline.privacy_functions import privacy_calc, privacy_calc_id\n",
    "from Pipeline.final_score import final_scoring\n",
    "from Pipeline.plotting.plot_functions import map_plotter, gemeente_lader, distribution_comparison\n",
    "from Pipeline.data_processing.df_comparison.df_comparer import correlation_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60801809",
   "metadata": {},
   "source": [
    "## 2. Variables\n",
    "The following section contains the variables and configuration used for the data synthesization. You can change these accordingly, depending on where the (input) data is located and where you would like to store the output (synthethic data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57c497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:44:20.743025Z",
     "start_time": "2023-01-30T10:44:20.738024Z"
    }
   },
   "outputs": [],
   "source": [
    "# The full data location of the dataset that will be used as input\n",
    "full_data_location = '<data location.csv>'\n",
    "\n",
    "# Columns to drop from the dataframe (default: empty)\n",
    "drop_cols = []\n",
    "# The name used for the synthetic files and subfolders\n",
    "name = '<name of result>'\n",
    "# The location where all the output such as the training dataset and synthetic dataset will be stored.\n",
    "output_location = os.path.join(os.getcwd(), 'Results\\\\' + name)\n",
    "# Y columns are the columns in the dataset for which the utility score will be calculated (default: age, gender). \n",
    "y_columns = ['age','gender']\n",
    "# ID columns are the columns in the dataset for which additional privacy scores will be calculated (default: age, gender, zip_code)\n",
    "id_columns = ['age', 'gender', 'zip_code']\n",
    "# Differential Privacy columns\n",
    "dp_columns = ['age', 'zip_code']\n",
    "\n",
    "# Variables used for drawing the graphs, col is the column which will be plotted for both the map and the distribution\n",
    "col = 'age'\n",
    "# The name of the column containing the zip_code4 data (default: zip_code)\n",
    "zip_code_column = 'zip_code'\n",
    "\n",
    "\n",
    "# The location of the synthpop file\n",
    "synthpop_file = os.path.join(os.getcwd(), 'R_scripts\\synthpop_script.R')\n",
    "# The location of the Rscript exe file\n",
    "# To find this open Rstudio, go to tools, global settings and copy the R version line:\n",
    "# Make sure all backwards slashes are changed to forward.\n",
    "rscript_loc = '//<pathto>/RforWindows/R-4.2.0' + '/bin/Rscript.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9dae6",
   "metadata": {},
   "source": [
    "## 3. Data processing\n",
    "The following section performs the necessary data (pre-)processing steps. The output folders will be created, including the training and holdout datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f55c37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:44:20.752031Z",
     "start_time": "2023-01-30T10:44:20.745024Z"
    }
   },
   "outputs": [],
   "source": [
    "# These variables do not require changing\n",
    "train_csv_location = output_location + '\\\\' + name + '_train.csv'\n",
    "holdout_csv_location = output_location + '\\\\' + name + '_holdout.csv'\n",
    "synth_csv_folder = output_location + '\\\\' + name + '_synths\\\\'\n",
    "synth_csv_location = synth_csv_folder + name + '_synthpop'\n",
    "synth_csv_folder = synth_csv_folder.replace('/','\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42caa75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:44:20.772021Z",
     "start_time": "2023-01-30T10:44:20.754025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the folder of the output location (only if it does not exist yet)\n",
    "if not os.path.exists(output_location):\n",
    "    os.makedirs(output_location)\n",
    "# Create the folder of for the synthetic datasets (only if it does not exist yet)\n",
    "if not os.path.exists(synth_csv_folder):\n",
    "    os.makedirs(synth_csv_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592b885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:44:47.373156Z",
     "start_time": "2023-01-30T10:44:20.774026Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function will make sure the file can be processed by synthpop\n",
    "# The function will print the column types: binary, categorical and continues columns\n",
    "full_data_process(file_loc=full_data_location, train_test_path=output_location, name=name, drop_cols=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca05f8e",
   "metadata": {},
   "source": [
    "# 4. Running Synthpop\n",
    "The code below will run the R script and use synthpop to create synthetic data <br>\n",
    "The script may take a while to run. <br>\n",
    "<br>\n",
    "Synthpop default processing method: <b>Visit order of empty columns first.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script uses the provided (local) R-libraries. \n",
    "# Verify if the script accesses the correct folder containing the synthpop package.\n",
    "print(synthpop_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286b188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:46:49.830769Z",
     "start_time": "2023-01-30T10:44:47.375158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This will run the Rscript and use synthpop to generate synthetic data\n",
    "synthpop = subprocess.Popen([rscript_loc, synthpop_file, train_csv_location, synth_csv_location],\n",
    "              stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "while True:\n",
    "    out = synthpop.stdout.readline()\n",
    "    if out.decode() == '' and synthpop.poll() == 0:\n",
    "        break\n",
    "    if out:\n",
    "        print(out.decode())\n",
    "    if out.decode() == 'NULL':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2d794",
   "metadata": {},
   "source": [
    "# 6. Apply differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "synthetic_data = pd.read_csv(synth_csv_location + '.csv')\n",
    "\n",
    "# Set privacy parameter and select columns to privatize\n",
    "epsilon, sensitivity = 0.8, 1\n",
    "columns = ['age', 'zip_code']\n",
    "\n",
    "# Add Laplace noise to create noisy and synthetic datasets\n",
    "noisy_data = synthetic_data.copy()\n",
    "for column in columns:\n",
    "    noisy_data[column] += np.random.laplace(0, scale=sensitivity/epsilon, size=len(synthetic_data)).round(0)\n",
    "\n",
    "# Write the noisy datasets to CSV files\n",
    "noisy_csv_location = synth_csv_folder + name + '_noisy.csv'\n",
    "noisy_data.to_csv(noisy_csv_location, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a145c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the column to compare\n",
    "column_to_compare = 'age'\n",
    "\n",
    "# Print basic statistics of the real and synthetic datasets\n",
    "print('Real data:')\n",
    "print(synthetic_data[column_to_compare].describe())\n",
    "print('\\nSynthetic data:')\n",
    "print(noisy_data[column_to_compare].describe())\n",
    "\n",
    "# Compute the mean absolute difference between the real and synthetic datasets\n",
    "mad = np.mean(np.abs(synthetic_data[column_to_compare] - noisy_data[column_to_compare]))\n",
    "\n",
    "print('\\nMean Absolute Difference:', mad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6c9ae",
   "metadata": {},
   "source": [
    "# 7. Apply k-anonimity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78832e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_round(x, base=5):\n",
    "    return int(base * round(float(x)/base))\n",
    "\n",
    "# Load dataset\n",
    "synthetic_data = pd.read_csv(synth_csv_location + '.csv')\n",
    "synthetic_data = synthetic_data.dropna(subset = ['zip_code'])\n",
    "\n",
    "# Define the columns that contain sensitive information\n",
    "sensitive_columns = id_columns\n",
    "\n",
    "# Apply k-anonimity measures (rounding of variables)\n",
    "synthetic_data['zip_code'] = synthetic_data['zip_code'].apply(lambda x: custom_round(x, base=5)).astype(\"float64\")\n",
    "synthetic_data['age'] = synthetic_data['age'].apply(lambda x: custom_round(x, base=5)).astype(\"float64\")\n",
    "\n",
    "# Group the data by the sensitive columns and count the number of rows in each group\n",
    "group_counts = synthetic_data.groupby(sensitive_columns).size().reset_index(name='count')\n",
    "\n",
    "# Determine the minimum group size (k) for each sensitive attribute combination\n",
    "min_counts = group_counts.groupby(sensitive_columns)['count'].min().reset_index(name='min_count')\n",
    "\n",
    "# Compute the overall minimum group size (k-anonymity level) as the minimum of all the individual k values\n",
    "k_anonymity_level = min_counts['min_count'].min()\n",
    "\n",
    "# Print the k-anonymity level\n",
    "print('The dataset has a k-anonymity level of', k_anonymity_level)\n",
    "print(group_counts)\n",
    "\n",
    "# Write the k-anonymity datasets to CSV files\n",
    "synthetic_data.to_csv(synth_csv_folder + name + '_kanonymity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfefb5",
   "metadata": {},
   "source": [
    "# 5. Evaluation\n",
    "The code below will evaluate the generated synthpop data against the holdout dataset using the metrics on utility, fidelity, and privacy. These outcomes can be used to evaluate the performance of synthetic data generation methods when compared to real data.<br>\n",
    "\n",
    "<b>Utility</b>: Utility refers to the usefulness of synthetic data for a particular task or analysis. In other words, how well does the synthetic data perform when used in place of real data? A synthetic dataset with high utility should be able to provide similar or equivalent results to those obtained using real data.<br>\n",
    "\n",
    "<b>Fidelity</b>: Fidelity refers to the degree to which the synthetic data accurately represents the real data. A synthetic dataset with high fidelity should be able to capture the key statistical properties of the real data, such as the mean, median, standard deviation, and distribution of variables.<br>\n",
    "\n",
    "<b>Privacy</b>: Privacy refers to the level of protection provided to individuals' personal information in the synthetic dataset. A synthetic dataset with high privacy should not be susceptible to re-identification attacks, meaning that it should not be possible to link an individual's identity to their personal information in the dataset.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66228a",
   "metadata": {},
   "source": [
    "## 5.1 Fidelity & Utility calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87def993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:46:57.143805Z",
     "start_time": "2023-01-30T10:46:49.832769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_results, ratio_results, reggre, classi = df_compare(train_csv_location,\n",
    "                                                        holdout_csv_location, \n",
    "                                                        synth_csv_folder,\n",
    "                                                        c=1,\n",
    "                                                        y_columns=y_columns,\n",
    "                                                        subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840981dc",
   "metadata": {},
   "source": [
    "### 5.1.1 Fidelity results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444a489",
   "metadata": {},
   "source": [
    "Fidelty evaluations compared to the real dataset.<br><br>\n",
    "    <b>dupe_numbers</b>: Number of duplicate records.<br>\n",
    "    <b>sum_%mean_diff</b>: This variable represents the sum of the percentage difference between the means of two sets of data. It can be used to quantify the degree of difference between the two sets of data.<br>\n",
    "    <b>sum_%median_diff</b>: This variable represents the sum of the percentage difference between the medians of two sets of data. It can be used to quantify the degree of difference between the two sets of data.<br>\n",
    "    <b>sum_%std_diff</b>: This variable represents the sum of the percentage difference between the standard deviations of two sets of data. It can be used to quantify the degree of difference between the two sets of data.<br>\n",
    "    <b>binary_val_count_diff</b>: This variable represents the difference in the count of binary values between two sets of data. It can be used to compare the frequency of occurrence of certain binary values between two sets of data.<br>\n",
    "    <b>correlation_norm</b>: This variable represents the normalized correlation between two sets of data. It can be used to measure the strength and direction of the linear relationship between the two sets of data.<br>\n",
    "    <b>real_or_snyth_acc</b>: This variable represents the accuracy of a machine learning model in classifying real versus synthetic data. It can be used to evaluate the performance of the model in distinguishing between real and synthetic data.<br>\n",
    "    <b>jenson_shannon</b>: This variable represents the Jensen-Shannon divergence between two probability distributions. It can be used to measure the dissimilarity between the two distributions.<br>\n",
    "    <b>total_variational_dist</b>: This variable represents the total variation distance between two probability distributions. It can be used to measure the distance between the two distributions.<br>\n",
    "    <b>wasserstein_dist</b>: This variable represents the Wasserstein distance between two probability distributions. It can be used to measure the distance between the two distributions, taking into account the underlying geometry of the space in which the distributions are defined.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813951ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:46:57.172805Z",
     "start_time": "2023-01-30T10:46:57.148807Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b4c02",
   "metadata": {},
   "source": [
    "### 5.1.2 Fidelity ratio results\n",
    "Calculated by dividing all results from a synthetic dataset by the holdout dataset. <br>\n",
    "\n",
    "Each result (expect for dupe_numbers) should near 1.0 to compare the synthetic data to the holdout dataset. This would conclude a good statistical comparable synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c443a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:46:57.190811Z",
     "start_time": "2023-01-30T10:46:57.175808Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio_results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fa2d7",
   "metadata": {},
   "source": [
    "### 5.1.3 Utility regression results\n",
    "Only showing the r2 score, the other scores calculated are the mse and the max error.<br>\n",
    "\n",
    "The r2 score (also known as the coefficient of determination) is a very important metric that is used to evaluate the performance of a regression-based machine learning model. It works by measuring the amount of variance in the predictions explained by the dataset. Simply put, it is the difference between the samples in the dataset and the predictions made by the model.<br>\n",
    "\n",
    "If the value of the r squared score is 1, it means that the model is perfect and if its value is 0, it means that the model will perform badly on an unseen dataset. The result should be compared to the score of the holdout dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d6d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:46:57.207804Z",
     "start_time": "2023-01-30T10:46:57.192808Z"
    }
   },
   "outputs": [],
   "source": [
    "reggre.xs('r2', level=1, drop_level=False).sort_values(by=reggre.columns[:1][0], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9b670",
   "metadata": {},
   "source": [
    "### 5.1.4 Utility classification results\n",
    "Only showing the accuracy, other scores calculated are the f1, recall and precision.\n",
    "\n",
    "Accuracy is the percentage of correct classifications that a trained machine learning model achieves, i.e., the number of correct predictions divided by the total number of predictions across all classes. Accuracy of 0 means the classifier always predicts the wrong label, whereas accuracy of 1 means that it always predicts the correct label.<br>\n",
    "\n",
    "Accuracy is an indicator for under- and overfitting and the value should be comparable to the holdout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dc935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:46:57.223807Z",
     "start_time": "2023-01-30T10:46:57.210806Z"
    }
   },
   "outputs": [],
   "source": [
    "classi.xs('accuracy', level=1, drop_level=False).sort_values(by=classi.columns[:1][0], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd166290",
   "metadata": {},
   "source": [
    "## 5.2 Privacy calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472a9ca",
   "metadata": {},
   "source": [
    "### 5.2.1 Calculations on entire dataset\n",
    "Calculate the privacy scores for the entire dataset, including all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cbab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:10.956875Z",
     "start_time": "2023-01-30T10:46:57.225806Z"
    }
   },
   "outputs": [],
   "source": [
    "privacy_results, privacy_ratio = privacy_calc(train_csv_location,\n",
    "                                              holdout_csv_location, \n",
    "                                              synth_csv_folder,\n",
    "                                              sample_per=75, \n",
    "                                              memory=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52c31e",
   "metadata": {},
   "source": [
    "### 5.2.2 Calculations on quassi-identifiers\n",
    "Calculate the privacy scores based on the quasi-identifiers indicated in the configuration step (2) of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_results_id, privacy_ratio_id = privacy_calc_id(train_csv_location,\n",
    "                                              holdout_csv_location, \n",
    "                                              synth_csv_folder,\n",
    "                                              id_columns,\n",
    "                                              sample_per=75, \n",
    "                                              memory=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb6b1d",
   "metadata": {},
   "source": [
    "### 5.2.3 Privacy score results\n",
    "DCR (Distance to Closest Record) and NNDR (Nearest Neighbour Distance Ratio) are  two evaluation metrics commonly used in the field of record linkage, which is the process of identifying records in different data sources that refer to the same entity. The values for the synthetic data should be comparable to the holdout dataset. Significantly lower scores indicate that records are close to the actual data and that the model overfits. \n",
    "\n",
    "The first two results are based on the entire dataset. The last two results are based on only the quasi-identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291ff40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:51:45.068249Z",
     "start_time": "2023-01-30T10:51:45.057244Z"
    }
   },
   "outputs": [],
   "source": [
    "privacy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44530e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:10.972875Z",
     "start_time": "2023-01-30T10:47:10.958877Z"
    }
   },
   "outputs": [],
   "source": [
    "privacy_ratio2 = privacy_ratio.T.add_suffix('_ratio')\n",
    "priv_both = pd.merge(privacy_results.T, privacy_ratio2, left_index=True, right_index=True)\n",
    "priv_both.sort_values(by='DCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8516cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_results_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_ratio2 = privacy_ratio_id.T.add_suffix('_ratio')\n",
    "priv_both = pd.merge(privacy_results_id.T, privacy_ratio2, left_index=True, right_index=True)\n",
    "priv_both.sort_values(by='DCR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1711a5",
   "metadata": {},
   "source": [
    "## 5.3 Final score\n",
    "In comparing a synthetic dataset with real data, it is important to evaluate each of these variables to ensure that the synthetic data is a suitable replacement for real data in a given analysis or task. A high level of utility and fidelity suggests that the synthetic data can be used with confidence, while a high level of privacy suggests that individuals' personal information is well protected.<br>\n",
    "\n",
    "<b>privacy</b>: Privacy score for the entire dataset<br>\n",
    "<b>privacy on ids</b>: Privacy score for the quasi-identifiers<br>\n",
    "<b>fidelity</b>: Statistical comparison between the datasets<br>\n",
    "<b>utlity</b>: Correlations between variables in the dataset<br>\n",
    "\n",
    "<b>For the final score, the lower the score per domain, the better the performance in that domain.</b><br> As explained by Rients:\n",
    "<i>For each of the three domains multiple evaluation methods have been used to assess the performance of each dataset. This results in a large number of scores, which can be difficult to interpret and draw conclusions from. To obtain a clearer understanding of the performance of each dataset, a final score has been calculated. These scores are calculated by aggregating the individual scores resulting in a clear overview of the performance of each dataset in each domain. Not every individual score contributes as much to the final aggregated score, because based on initial results certain methods such as calculating the sum percentage difference of the standard deviation returned unstable results. All aggregated scores have been calculated in a penalty like matter, meaning that the lower the score is, the better the dataset has performed.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466e2ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:11.017873Z",
     "start_time": "2023-01-30T10:47:10.973875Z"
    }
   },
   "outputs": [],
   "source": [
    "end_score, priv_score, priv_score_id, fidel_score, ml_score, fin_frame = final_scoring(ratio_results, privacy_ratio, privacy_ratio_id, reggre, classi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d0e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:11.028876Z",
     "start_time": "2023-01-30T10:47:11.019874Z"
    }
   },
   "outputs": [],
   "source": [
    "end_score.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278c335",
   "metadata": {},
   "source": [
    "## 5.4 Graph plotting\n",
    "For visual comparison of the results various graphs and plots can be used. These are computed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce0702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:11.037876Z",
     "start_time": "2023-01-30T10:47:11.033872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change this to one of the columns to alter the graphs.\n",
    "col = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03fdd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:12.460886Z",
     "start_time": "2023-01-30T10:47:11.039874Z"
    }
   },
   "outputs": [],
   "source": [
    "gemeentes = gemeente_lader()\n",
    "df_real, synth_frame = data_loader(train_csv_location, holdout_csv_location, synth_csv_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35c7c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:13.837888Z",
     "start_time": "2023-01-30T10:47:12.462881Z"
    }
   },
   "outputs": [],
   "source": [
    "plots = []\n",
    "for frame in synth_frame:\n",
    "    df = pd.read_csv(synth_frame[frame])\n",
    "    plots.append(map_plotter(df_real, df, gemeentes, frame, column=col, zip_code=zip_code_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6f46f",
   "metadata": {},
   "source": [
    "### 5.4.1 Geographical spread and visual\n",
    "Showing averages of a column grouped on zip code/municipality. Atleast 25 participants need to have the same zip code to be included in the visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3868ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:14.464898Z",
     "start_time": "2023-01-30T10:47:13.839890Z"
    }
   },
   "outputs": [],
   "source": [
    "plots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c1830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:15.004898Z",
     "start_time": "2023-01-30T10:47:14.466892Z"
    }
   },
   "outputs": [],
   "source": [
    "plots[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc422fed",
   "metadata": {},
   "source": [
    "### 5.4.2 Univariate distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff5cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:15.011894Z",
     "start_time": "2023-01-30T10:47:15.006895Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_real[col].min(), df_real[col].max(), df_real[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4bdf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:15.016896Z",
     "start_time": "2023-01-30T10:47:15.013897Z"
    }
   },
   "outputs": [],
   "source": [
    "# This variable could be changed.\n",
    "# If there are to many bars in the distribution increasing the split nr will benefit this.\n",
    "# With binary columns change it to 0.5\n",
    "split = 6\n",
    "\n",
    "# Change this to one of the columns to alter the graphs.\n",
    "col = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1679d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:15.366897Z",
     "start_time": "2023-01-30T10:47:15.020898Z"
    }
   },
   "outputs": [],
   "source": [
    "dist  = []\n",
    "for frame in synth_frame:\n",
    "    df = pd.read_csv(synth_frame[frame])\n",
    "    dist.append(distribution_comparison(df_real, df, column=col, step_split=split, name=frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ef1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:16.032899Z",
     "start_time": "2023-01-30T10:47:15.368896Z"
    }
   },
   "outputs": [],
   "source": [
    "dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e6382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T10:47:16.693903Z",
     "start_time": "2023-01-30T10:47:16.034900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e5e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993580c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
